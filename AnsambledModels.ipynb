{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AnsambledModels.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuEwMNtDRgFK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from abc import ABCMeta, abstractmethod"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UtilsForMachineLearning(metaclass=ABCMeta):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.__models = []\n",
        "    self.__xTrain = None\n",
        "    self.__yTrain = None\n",
        "    self.__xTest = None\n",
        "    self.__yTest = None\n",
        "\n",
        "  def createModel(self, modelClass, modelName, **kwargs):\n",
        "    model = modelClass(**kwargs)\n",
        "    self.getModels().append((modelName, model))\n",
        "   \n",
        "  def fitAllModels(self):\n",
        "    try:    \n",
        "      for modelName, model in self.getModels():\n",
        "        print(\"Training...\", modelName)\n",
        "        model.fit(self.getXTrain(), self.getYTrain())\n",
        "      \n",
        "      return \"Models had trained succesfully\"\n",
        "    except ValueError as error:\n",
        "      return error\n",
        "\n",
        "  @abstractmethod\n",
        "  def predictTestingData(self, dataFrame):\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def createDfPrediction(self, varType=None):\n",
        "    pass\n",
        "\n",
        "  @staticmethod\n",
        "  def calc_cohen_cappa(dataFrame, predictColName=\"prediction\", answerColName=\"answer\", weights=\"quadratic\"):\n",
        "    return cohen_kappa_score(dataFrame[predictColName], dataFrame[answerColName], weights=weights)\n",
        "\n",
        "  def setTestDataFrame(self, xTest, yTest):\n",
        "    self.__xTest = xTest\n",
        "    self.__yTest = yTest\n",
        "\n",
        "  def setTrainDataFrame(self, xTrain, yTrain):\n",
        "    self.__xTrain = xTrain\n",
        "    self.__yTrain = yTrain\n",
        "   \n",
        "  def getXTrain(self):\n",
        "    return self.__xTrain\n",
        "  \n",
        "  def getYTrain(self):\n",
        "    return self.__yTrain\n",
        "  \n",
        "  def getXTest(self):\n",
        "    return self.__xTest\n",
        "  \n",
        "  def getYTest(self):\n",
        "    return self.__yTest\n",
        "\n",
        "  def getModels(self):\n",
        "    return self.__models\n",
        "  \n",
        "class VoterModel(UtilsForMachineLearning):\n",
        "  \n",
        "  def createDfPrediction(self, varType=None):\n",
        "    finalDf = pd.DataFrame(self.getYTest())\n",
        "    for modelName, model in self.getModels():\n",
        "      print(\"Predict...\", modelName)\n",
        "      targetName = \"target_\" + modelName\n",
        "\n",
        "      finalDf[targetName] = model.predict(self.getXTest())\n",
        "\n",
        "      if not varType:\n",
        "        varType = self.getYTest().dtype\n",
        "      \n",
        "      finalDf[targetName] = finalDf[targetName].astype(varType)\n",
        "      finalDf[\"weights_\" + modelName] = cohen_kappa_score(finalDf[targetName], self.getYTest(), weights=\"quadratic\")\n",
        "\n",
        "    return finalDf\n",
        "  \n",
        "  def predictTestingData(self, dataFrame):\n",
        "    votes = {}\n",
        "    final_responses = []\n",
        "\n",
        "    for _, row in dataFrame.iterrows():\n",
        "      for col in dataFrame.columns:\n",
        "        if col.startswith(\"target\"):\n",
        "          try:\n",
        "            votes[row[col]] += row[col.replace(\"target\", \"weights\")]\n",
        "          except:\n",
        "            votes[row[col]] = row[col.replace(\"target\", \"weights\")]\n",
        "\n",
        "      m_v = max([v for _,v in votes.items()])\n",
        "\n",
        "      for key, item in votes.items():\n",
        "        if item == m_v:\n",
        "          final_responses.append(int(key))\\\n",
        "\n",
        "      votes = {}\n",
        "\n",
        "    modelAnswersDf = pd.DataFrame({\"prediction\" : final_responses, \"answer\" : self.getYTest()})\n",
        "    return {\"dataFrame\" : modelAnswersDf, \"cohhen_cappa_score\" : VoterModel.calc_cohen_cappa(modelAnswersDf)}\n",
        "\n",
        "class LGBPredictionModel(UtilsForMachineLearning):\n",
        "\n",
        "  def createDfPrediction(self, varType=None):\n",
        "    finalDf = pd.DataFrame(self.getYTrain())\n",
        "    for modelName, model in self.getModels():\n",
        "      print(\"Predict...\", modelName)\n",
        "      targetName = \"target_\" + modelName\n",
        "\n",
        "      finalDf[targetName] = model.predict(self.getXTrain())\n",
        "\n",
        "      if not varType:\n",
        "        varType = self.getYTrain().dtype\n",
        "      \n",
        "      finalDf[targetName] = finalDf[targetName].astype(varType)\n",
        "      finalDf[\"weights_\" + modelName] = cohen_kappa_score(finalDf[targetName], self.getYTrain(), weights=\"quadratic\")\n",
        "\n",
        "    return finalDf\n",
        "  \n",
        "  def predictTestingData(self, dataFrame):\n",
        "    fitDataFrame = dataFrame.drop(columns=pd.DataFrame(self.getYTrain()).columns)\n",
        "    print(fitDataFrame)\n",
        "\n",
        "    lgbModel = lgb.LGBMRegressor()\n",
        "    lgbModel.fit(fitDataFrame, self.getYTrain())\n",
        "\n",
        "    finalDf = pd.DataFrame()\n",
        "    for modelName, model in self.getModels():\n",
        "      targetName = \"target_\" + modelName\n",
        "\n",
        "      finalDf[targetName] = model.predict(self.getXTest())\n",
        "\n",
        "      varType = self.getYTest().dtype\n",
        "      \n",
        "      finalDf[targetName] = finalDf[targetName].astype(varType)\n",
        "      finalDf[\"weights_\" + modelName] = dataFrame[\"weights_\" + modelName]\n",
        "      \n",
        "    prediction = np.round(lgbModel.predict(finalDf))\n",
        "\n",
        "    modelAnswersDf = pd.DataFrame({\"prediction\" : prediction, \"answer\" : self.getYTest()})\n",
        "\n",
        "    return {\"dataFrame\" : modelAnswersDf, \"cohhen_cappa_score\" : LGBPredictionModel.calc_cohen_cappa(modelAnswersDf)}\n",
        "\n"
      ],
      "metadata": {
        "id": "kSsl9R8nDuak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"http://video.ittensive.com/machine-learning/prudential/train.csv.gz\")\n",
        "\n",
        "train[\"Product_Info_2_1\"] = train[\"Product_Info_2\"].str.slice(0, 1)\n",
        "train[\"Product_Info_2_2\"] = pd.to_numeric(train[\"Product_Info_2\"].str.slice(1, 2))\n",
        "\n",
        "for i in train[\"Product_Info_2_1\"]:\n",
        "  train[\"Product_Info_2_1\" + i] = train[\"Product_Info_2_1\"].isin([i]).astype(\"int8\")\n",
        "\n",
        "train.drop(labels=[\"Product_Info_2\", \"Product_Info_2_1\"], axis=1, inplace=True)\n",
        "\n",
        "train[\"Employment_Info_1\"].fillna(value=0, inplace=True)\n",
        "train[\"Employment_Info_4\"].fillna(value=0, inplace=True)\n",
        "train[\"Employment_Info_6\"].fillna(value=0, inplace=True)\n",
        "train[\"Insurance_History_5\"].fillna(value=0, inplace=True)\n",
        "train[\"Family_Hist_2\"].fillna(value=0, inplace=True)\n",
        "train[\"Family_Hist_3\"].fillna(value=0, inplace=True)\n",
        "train[\"Family_Hist_4\"].fillna(value=0, inplace=True)\n",
        "train[\"Family_Hist_5\"].fillna(value=0, inplace=True)\n",
        "train[\"Medical_History_1\"].fillna(value=0, inplace=True)\n",
        "train[\"Medical_History_10\"].fillna(value=0, inplace=True)\n",
        "train[\"Medical_History_15\"].fillna(value=0, inplace=True)\n",
        "train[\"Medical_History_24\"].fillna(value=0, inplace=True)\n",
        "train[\"Medical_History_32\"].fillna(value=0, inplace=True)\n",
        "train[\"Employment_Info_1\"].fillna(value=0, inplace=True)\n",
        "train[\"Employment_Info_1\"].fillna(value=0, inplace=True)\n",
        "train[\"Employment_Info_1\"].fillna(value=0, inplace=True)\n",
        "train[\"Employment_Info_1\"].fillna(value=0, inplace=True)"
      ],
      "metadata": {
        "id": "s44oFo50RtGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_groups = [\"Insurance_History\", \"InsuredInfo\", \"Medical_Keyword\", \"Family_Hist\", \"Medical_History\", \"Product_Info\"]\n",
        "columns = [\"Wt\", \"Ht\", \"Ins_Age\", \"BMI\"]\n",
        "\n",
        "for cg in column_groups:\n",
        "  columns.extend(train.columns[train.columns.str.startswith(cg)])\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(pd.DataFrame(train, columns=columns))\n",
        "\n",
        "data_train, data_test = train_test_split(train, test_size=0.2)\n",
        "\n",
        "data_train = pd.DataFrame(data_train)\n",
        "data_test = pd.DataFrame(data_test)\n",
        "\n",
        "x_train = pd.DataFrame(data_train, columns=columns)\n",
        "y_train = data_train[\"Response\"]\n",
        "\n",
        "x_test = pd.DataFrame(data_test, columns=columns)\n",
        "y_test = pd.DataFrame(data_test[\"Response\"])"
      ],
      "metadata": {
        "id": "R-sN6O1IR9II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voterModel = VoterModel()\n",
        "\n",
        "voterModel.setTrainDataFrame(x_train, y_train)\n",
        "voterModel.setTestDataFrame(x_test, data_test[\"Response\"])\n",
        "\n",
        "voterModel.createModel(lgb.LGBMRegressor, \"lgb\", max_iter=1000)\n",
        "voterModel.createModel(KNeighborsClassifier, \"knn_10\", n_neighbors=10)\n",
        "voterModel.createModel(LogisticRegression, \"log_regr\", class_weight=\"balanced\", multi_class=\"multinomial\")\n",
        "voterModel.createModel(LinearSVC, \"svc\", max_iter=1000)\n",
        "voterModel.createModel(SGDClassifier, \"sgd\", max_iter=10000)\n",
        "voterModel.createModel(DecisionTreeClassifier, \"tree\")\n",
        "voterModel.createModel(RandomForestClassifier, \"random_forest\")\n",
        "voterModel.createModel(XGBClassifier, \"xgb\")\n",
        "\n",
        "print(voterModel.fitAllModels())\n",
        "finalDataFrame = voterModel.createDfPrediction()\n",
        "voterAnswers = voterModel.predictTestingData(finalDataFrame)"
      ],
      "metadata": {
        "id": "T7r50MEBRFbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(voterAnswers)"
      ],
      "metadata": {
        "id": "_2cwXEZrZf9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbModel = LGBPredictionModel()\n",
        "\n",
        "lgbModel.setTrainDataFrame(x_train, y_train)\n",
        "lgbModel.setTestDataFrame(x_test, data_test[\"Response\"])\n",
        "\n",
        "lgbModel.createModel(lgb.LGBMRegressor, \"lgb\", max_iter=1000)\n",
        "lgbModel.createModel(KNeighborsClassifier, \"knn_10\", n_neighbors=10)\n",
        "lgbModel.createModel(LogisticRegression, \"log_regr\", class_weight=\"balanced\", multi_class=\"multinomial\")\n",
        "lgbModel.createModel(LinearSVC, \"svc\", max_iter=1000)\n",
        "lgbModel.createModel(SGDClassifier, \"sgd\", max_iter=10000)\n",
        "lgbModel.createModel(DecisionTreeClassifier, \"tree\")\n",
        "lgbModel.createModel(RandomForestClassifier, \"random_forest\")\n",
        "lgbModel.createModel(XGBClassifier, \"xgb\")\n",
        "\n",
        "print(lgbModel.fitAllModels())"
      ],
      "metadata": {
        "id": "sIWMmaGZd92J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalDataFrame = lgbModel.createDfPrediction()\n",
        "lgbAnswers = lgbModel.predictTestingData(finalDataFrame)"
      ],
      "metadata": {
        "id": "uMAK0-YYeG_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lgbAnswers)"
      ],
      "metadata": {
        "id": "QUpA_JsykP1h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}